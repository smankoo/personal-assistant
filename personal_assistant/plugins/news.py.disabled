import feedparser
import requests
from bs4 import BeautifulSoup

from personal_assistant.tools.caching import cached_output, get_cache, set_cache

RSS_FEEDS = {
    # Technology
    "WIRED": {"url": "https://www.wired.com/feed/rss", "enabled": True},
    "The Verge": {"url": "https://www.theverge.com/rss/index.xml", "enabled": True},
    "TechCrunch": {"url": "https://techcrunch.com/feed/", "enabled": True},
    "Ars Technica": {"url": "https://arstechnica.com/feed/", "enabled": True},
    "Hacker News": {"url": "https://hnrss.org/frontpage", "enabled": True},
    # Indian News
    "NDTV India": {
        "url": "https://feeds.feedburner.com/ndtvnews-india-news",
        "enabled": False,
    },
    "Times of India": {
        "url": "https://timesofindia.indiatimes.com/rssfeeds/-2128936835.cms",
        "enabled": False,
    },
    "Hindustan Times": {
        "url": "https://www.hindustantimes.com/rss/topnews/rssfeed.xml",
        "enabled": False,
    },
    "The Hindu": {
        "url": "https://www.thehindu.com/feeder/default.rss",
        "enabled": True,
    },
    "Indian Express": {
        "url": "https://indianexpress.com/section/india/feed/",
        "enabled": False,
    },
    # Canadian News
    "CBC News": {"url": "https://www.cbc.ca/cmlink/rss-topstories", "enabled": True},
    "The Globe and Mail": {
        "url": "https://www.theglobeandmail.com/arc/outboundfeeds/rss/category/canada/",
        "enabled": True,
    },
    "Toronto Star": {
        "url": "https://www.thestar.com/content/thestar/feed.RSSManagerServlet.topstories.rss",
        "enabled": True,
    },
    "CTV News": {"url": "https://www.ctvnews.ca/rss/TopStories", "enabled": True},
    # Personal Finance
    "Financial Post": {
        "url": "https://financialpost.com/category/personal-finance/feed/",
        "enabled": True,
    },
    "The Simple Dollar": {
        "url": "https://www.thesimpledollar.com/feed/",
        "enabled": True,
    },
    # Parenting and Family
    "Parents Magazine": {
        "url": "https://www.parents.com/feeds/rss.xml",
        "enabled": True,
    },
    "Today's Parent": {"url": "https://www.todaysparent.com/feed/", "enabled": True},
    # Professional Growth
    "Harvard Business Review": {"url": "https://hbr.org/feed", "enabled": True},
    "McKinsey Insights": {
        "url": "https://www.mckinsey.com/insights/rss",
        "enabled": True,
    },
    # Cricket and Sports
    "ESPN Cricinfo": {
        "url": "https://www.espncricinfo.com/rss/content/story/feeds/0.xml",
        "enabled": True,
    },
    "Sportsnet": {"url": "https://www.sportsnet.ca/feed/", "enabled": False},
    # Consumer Technology and Reviews
    "Gadget Review": {"url": "https://www.gadgetreview.com/feed", "enabled": False},
    "CNET": {"url": "https://www.cnet.com/rss/all/", "enabled": False},
}

ARTICLE_LIMIT = 5  # Limit to 5 articles per source


# Function to clean HTML tags from text
def clean_html(raw_html):
    soup = BeautifulSoup(raw_html, "html.parser")
    return soup.get_text(separator=" ").strip()


# Function to fetch and parse RSS feed
def fetch_rss(feed_name, feed_url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(feed_url, headers=headers, timeout=10, verify=False)

        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx, 5xx)
        feed = feedparser.parse(response.text)
        articles = [
            {
                "title": entry.title,
                "summary": clean_html(entry.get("summary", "No summary available")),
                "link": entry.link,
                "published": entry.get("published", "Unknown"),
            }
            for entry in feed.entries[:ARTICLE_LIMIT]
        ]
        return {"source": feed_name, "articles": articles}
    except requests.exceptions.RequestException as e:
        return {"source": feed_name, "error": f"HTTP error: {str(e)}"}
    except Exception as e:
        return {"source": feed_name, "error": f"Parsing error: {str(e)}"}


# Function to fetch news from enabled sources
def fetch_news():
    news = []
    for name, config in RSS_FEEDS.items():
        if config["enabled"]:
            # print(f"Fetching news from {name}...")
            feed_result = fetch_rss(name, config["url"])
            news.append(feed_result)
    return news


@cached_output(max_age_seconds=3600)  # Cache expires in 1 hour
def fetch_news_formatted():
    news = fetch_news()
    formatted_news = ""
    for source in news:
        formatted_news += f"## {source['source']}\n\n"
        if "error" in source:
            formatted_news += f"**Error:** {source['error']}\n\n"
        else:
            for article in source["articles"]:
                formatted_news += f"### {article['title']}\n"
                if "summary" in article and article["summary"] != "":
                    formatted_news += f"**Summary:**\n\n> {article['summary']}\n\n"
                # formatted_news += f"[Read more]({article['link']})\n\n"
    return formatted_news


def get_output():
    formatted_news = fetch_news_formatted()

    return {
        "plugin_name": "news",
        "output": f"Here are today's top news headlines: \n{formatted_news}",
    }


if __name__ == "__main__":
    output = get_output()
    print(output["output"])
